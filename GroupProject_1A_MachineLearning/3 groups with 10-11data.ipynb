{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 452 entries, 0 to 451\n",
      "Data columns (total 26 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   W_PCT       452 non-null    float64\n",
      " 1   AGE         452 non-null    int64  \n",
      " 2   FGM         452 non-null    float64\n",
      " 3   FGA         452 non-null    float64\n",
      " 4   FG_PCT      452 non-null    float64\n",
      " 5   FG3M        452 non-null    float64\n",
      " 6   FG3A        452 non-null    float64\n",
      " 7   FG3_PCT     452 non-null    float64\n",
      " 8   FTM         452 non-null    float64\n",
      " 9   FTA         452 non-null    float64\n",
      " 10  FT_PCT      452 non-null    float64\n",
      " 11  OREB        452 non-null    float64\n",
      " 12  DREB        452 non-null    float64\n",
      " 13  REB         452 non-null    float64\n",
      " 14  AST         452 non-null    float64\n",
      " 15  TOV         452 non-null    float64\n",
      " 16  STL         452 non-null    float64\n",
      " 17  BLK         452 non-null    float64\n",
      " 18  BLKA        452 non-null    float64\n",
      " 19  PF          452 non-null    float64\n",
      " 20  PFD         452 non-null    float64\n",
      " 21  PTS         452 non-null    float64\n",
      " 22  PLUS_MINUS  452 non-null    float64\n",
      " 23  FP          452 non-null    float64\n",
      " 24  DD2         452 non-null    int64  \n",
      " 25  TD3         452 non-null    int64  \n",
      "dtypes: float64(23), int64(3)\n",
      "memory usage: 91.9 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='W_PCT', ylabel='count'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as pyplot\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "# step1 loading data,check null value\n",
    "player=pd.read_csv('2010-11.csv',sep=',')\n",
    "player.info()\n",
    "player.isnull().sum()\n",
    "# step 2, processing data,set up unique labels and group names,use labelEncoder to set up the ratio to 0,1,\n",
    "# use sns to shrew it into  a graph\n",
    "# may play with the bins and make the bins lean more towards the high win ratio\n",
    "bins=(-0.1,0.5,0.7,1.0)\n",
    "group_names=['low','medium','high']\n",
    "player['W_PCT']=pd.cut(player['W_PCT'], bins=bins,labels=group_names)\n",
    "player['W_PCT'].unique()\n",
    "\n",
    "label_ratio=LabelEncoder()\n",
    "player['W_PCT']=label_ratio.fit_transform(player['W_PCT'].astype(str))\n",
    "\n",
    "sns.countplot(x=player['W_PCT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_PCT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FG3_PCT</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>...</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>BLKA</th>\n",
       "      <th>PF</th>\n",
       "      <th>PFD</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>FP</th>\n",
       "      <th>DD2</th>\n",
       "      <th>TD3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.297</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>10.7</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>18.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.275</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>3.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.416</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.357</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>6.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>35.5</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>18.6</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.154</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.315</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>9.5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.435</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>44.2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>23.8</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>16.8</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>34.3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.337</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>34.6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>4.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.108</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>29.9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.448</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.345</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>21.4</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>31.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.367</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>27.8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>11.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    W_PCT  AGE  FGM   FGA  FG_PCT  FG3M  FG3A  FG3_PCT  FTM  FTA  ...  STL  \\\n",
       "0       1   26  3.7   9.9   0.375   1.2   4.0    0.297  2.1  2.4  ...  0.6   \n",
       "1       2   26  1.4   2.4   0.566   0.0   0.0    0.000  0.4  0.8  ...  0.3   \n",
       "2       1   26  1.6   3.6   0.435   0.1   0.7    0.167  0.9  1.3  ...  0.6   \n",
       "3       1   24  2.3   6.4   0.356   0.8   3.0    0.275  1.1  1.6  ...  0.6   \n",
       "4       2   31  3.8   9.2   0.416   1.6   4.5    0.357  1.2  1.6  ...  0.5   \n",
       "5       2   25  6.7  12.0   0.557   0.0   0.1    0.500  1.9  2.4  ...  0.8   \n",
       "6       1   26  8.0  16.1   0.496   0.0   0.0    0.000  2.7  3.5  ...  0.6   \n",
       "7       1   27  2.9   6.1   0.476   0.1   0.4    0.154  1.5  2.0  ...  0.5   \n",
       "8       1   23  1.7   3.9   0.444   0.4   1.0    0.353  0.4  0.5  ...  0.3   \n",
       "9       1   20  2.0   5.0   0.394   0.6   1.8    0.315  1.1  1.5  ...  0.7   \n",
       "10      1   24  2.2   4.7   0.458   0.3   0.9    0.333  1.3  1.6  ...  0.7   \n",
       "11      1   28  9.5  19.0   0.502   0.1   0.3    0.435  6.1  7.7  ...  0.9   \n",
       "12      1   24  3.9   6.9   0.568   0.0   0.0    0.000  1.8  2.2  ...  0.7   \n",
       "13      1   28  3.7   7.0   0.528   0.0   0.1    0.000  1.7  2.6  ...  0.9   \n",
       "14      1   24  6.7  15.0   0.445   0.1   0.3    0.222  3.4  4.4  ...  1.5   \n",
       "15      2   27  5.0  11.3   0.445   0.9   2.7    0.337  3.1  4.5  ...  1.5   \n",
       "16      2   35  4.8  10.4   0.460   0.0   0.5    0.108  3.1  3.6  ...  1.4   \n",
       "17      1   25  8.0  17.8   0.448   1.2   3.4    0.345  4.3  5.3  ...  0.5   \n",
       "18      2   30  4.0   8.5   0.467   0.6   1.5    0.367  3.3  4.2  ...  1.3   \n",
       "19      1   31  2.2   5.1   0.426   0.8   2.2    0.356  0.9  1.1  ...  0.3   \n",
       "\n",
       "    BLK  BLKA   PF  PFD   PTS  PLUS_MINUS    FP  DD2  TD3  \n",
       "0   0.1   0.7  1.9  2.1  10.7        -2.8  18.5    2    0  \n",
       "1   0.3   0.3  2.3  0.7   3.1         0.7   9.6    2    0  \n",
       "2   0.0   0.4  1.2  1.2   4.2        -2.6   9.2    0    0  \n",
       "3   0.0   0.2  1.2  1.5   6.5         0.5  12.3    0    0  \n",
       "4   0.1   0.6  2.8  1.5  10.5         1.8  18.6    1    0  \n",
       "5   1.0   0.5  2.5  2.3  15.3         0.6  35.5   36    0  \n",
       "6   1.9   1.1  2.9  3.1  18.6        -2.0  39.0   37    0  \n",
       "7   0.2   0.3  2.0  1.6   7.4        -2.0  13.4    0    0  \n",
       "8   0.6   0.1  2.1  0.6   4.2         0.2   9.5    0    0  \n",
       "9   0.3   0.5  1.5  1.1   5.6        -2.3  12.5    0    0  \n",
       "10  0.3   0.7  1.7  1.1   5.9        -4.9  13.0    0    0  \n",
       "11  1.9   1.5  3.5  6.1  25.3         0.8  44.2   26    0  \n",
       "12  1.2   0.7  3.7  2.2   9.6        -1.8  23.8   11    0  \n",
       "13  1.2   0.7  2.8  2.8   9.1        -5.5  27.9    7    0  \n",
       "14  0.8   1.2  2.8  3.6  16.8        -3.8  34.3   17    0  \n",
       "15  0.6   0.3  1.6  3.7  14.1         2.4  34.6   11    3  \n",
       "16  0.1   0.7  2.1  2.8  12.7         3.1  29.9   11    0  \n",
       "17  0.7   0.7  2.4  4.5  21.4        -4.8  31.7    2    0  \n",
       "18  1.2   0.6  1.8  3.1  11.7        -0.5  27.8    4    0  \n",
       "19  0.3   0.3  1.9  1.1   6.1        -2.6  11.8    2    0  \n",
       "\n",
       "[20 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.head(20)\n",
    "# label(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    238\n",
       "2    152\n",
       "0     62\n",
       "Name: W_PCT, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player['W_PCT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3, seperate the dataset as response variable and feature variables, get ready for model\n",
    "X=player.drop('W_PCT',axis=1)\n",
    "y=player['W_PCT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4,Use train_test_split(package) to split the data to  Train data and Test data, default test_size 25%\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 5 ,Scale up the data Applying Standart scaling to get optimized result eg, big number overweight the impact of small number\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "# X_test[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6,choose classifier\n",
    "# RANDOM FOREST -Least amount of parts to fine-tune,\n",
    "# used for a medium sized data set\n",
    "# 1,create randomForest variable,2,fit the training data to it,3 predict\n",
    "rfc=RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(X_train,y_train)\n",
    "pred_rfc=rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test[:20]\n",
    "# the test data print out have been sacled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 1, 1, 2, 1, 0, 0, 2, 2, 1, 2, 1, 0, 1, 1, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rfc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.08      0.12        12\n",
      "           1       0.83      0.82      0.82        60\n",
      "           2       0.43      0.63      0.51        19\n",
      "\n",
      "    accuracy                           0.68        91\n",
      "   macro avg       0.50      0.51      0.49        91\n",
      "weighted avg       0.67      0.68      0.67        91\n",
      "\n",
      "[[ 1  3  8]\n",
      " [ 3 49  8]\n",
      " [ 0  7 12]]\n"
     ]
    }
   ],
   "source": [
    "# check the performence of the model\n",
    "print(classification_report(y_test,pred_rfc))\n",
    "print(confusion_matrix(y_test,pred_rfc))\n",
    "# the consusion matrix report shows a lot of miss lable of 'low' and 'high'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM classifier\n",
    "clf=svm.SVC()\n",
    "clf.fit(X_train,y_train)\n",
    "pred_clf=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.08      0.14        12\n",
      "           1       0.82      0.82      0.82        60\n",
      "           2       0.38      0.58      0.46        19\n",
      "\n",
      "    accuracy                           0.67        91\n",
      "   macro avg       0.57      0.49      0.47        91\n",
      "weighted avg       0.68      0.67      0.65        91\n",
      "\n",
      "[[ 1  3  8]\n",
      " [ 1 49 10]\n",
      " [ 0  8 11]]\n"
     ]
    }
   ],
   "source": [
    "# check performence of model\n",
    "print(classification_report(y_test,pred_clf))\n",
    "print(confusion_matrix(y_test,pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.08      0.12        12\n",
      "           1       0.79      0.80      0.79        60\n",
      "           2       0.35      0.47      0.40        19\n",
      "\n",
      "    accuracy                           0.64        91\n",
      "   macro avg       0.46      0.45      0.44        91\n",
      "weighted avg       0.62      0.64      0.62        91\n",
      "\n",
      "[[ 1  4  7]\n",
      " [ 2 48 10]\n",
      " [ 1  9  9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cxxme\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Neural Network classifier\n",
    "# works well with huge amount of data\n",
    "mlpc=MLPClassifier(hidden_layer_sizes=(11,11,11),max_iter=500)\n",
    "mlpc.fit(X_train,y_train)\n",
    "pred_mlpc=mlpc.predict(X_test)\n",
    "print(classification_report(y_test,pred_mlpc))\n",
    "print(confusion_matrix(y_test,pred_mlpc))\n",
    "# A convergence point is a machine learning models localized optimal state. \n",
    "# It basically means that the variables within the model have the best posible values in order to\n",
    "# predict a target feature based on another set of features. In MLP, these variables are the weights within each neuron. \n",
    "# Generally, when a data set doesn't represent a organized and discernable pattern, machine learning algorithms might not be able to find a convergence point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last step, use the choosen model and given new feature data to predict \n",
    "Xnew=[[23,1.6,3.2,0.513,0,0,0,0.6,0.8,0.677,0.8,1.6,2.4,0.3,0.4,0.3,0.5,0.3,0.9,0.8,3.8,-1.8,9.1,1,0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew=sc.transform(Xnew)\n",
    "ynew=clf.predict(Xnew)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
