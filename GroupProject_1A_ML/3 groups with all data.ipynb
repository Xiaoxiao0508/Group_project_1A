{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2849 entries, 0 to 2848\n",
      "Data columns (total 26 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   W_PCT            2849 non-null   float64\n",
      " 1   AGE              2849 non-null   int64  \n",
      " 2   FGM              2849 non-null   float64\n",
      " 3   FGA              2849 non-null   float64\n",
      " 4   FG_PCT           2849 non-null   float64\n",
      " 5   FG3M             2849 non-null   float64\n",
      " 6   FG3A             2849 non-null   float64\n",
      " 7   FG3_PCT          2849 non-null   float64\n",
      " 8   FTM              2849 non-null   float64\n",
      " 9   FTA              2849 non-null   float64\n",
      " 10  FT_PCT           2849 non-null   float64\n",
      " 11  OREB             2849 non-null   float64\n",
      " 12  DREB             2849 non-null   float64\n",
      " 13  REB              2849 non-null   float64\n",
      " 14  AST              2849 non-null   float64\n",
      " 15  TOV              2849 non-null   float64\n",
      " 16  STL              2849 non-null   float64\n",
      " 17  BLK              2849 non-null   float64\n",
      " 18  BLKA             2849 non-null   float64\n",
      " 19  PF               2849 non-null   float64\n",
      " 20  PFD              2849 non-null   float64\n",
      " 21  PTS              2849 non-null   float64\n",
      " 22  PLUS_MINUS       2849 non-null   float64\n",
      " 23  NBA_FANTASY_PTS  2849 non-null   float64\n",
      " 24  DD2              2849 non-null   int64  \n",
      " 25  TD3              2849 non-null   int64  \n",
      "dtypes: float64(23), int64(3)\n",
      "memory usage: 578.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='W_PCT', ylabel='count'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as pyplot\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "# step1 loading data,check null value\n",
    "player=pd.read_csv('2010-16.csv',sep=',')\n",
    "player.info()\n",
    "player.isnull().sum()\n",
    "# step 2, processing data,set up unique labels and group names,use labelEncoder to set up the ratio to 0,1,\n",
    "# use sns to shrew it into  a graph\n",
    "# may play with the bins and make the bins lean more towards the high win ratio\n",
    "bins=(-0.1,0.5,0.7,1.0)\n",
    "group_names=['low','medium','high']\n",
    "player['W_PCT']=pd.cut(player['W_PCT'], bins=bins,labels=group_names)\n",
    "player['W_PCT'].unique()\n",
    "\n",
    "label_ratio=LabelEncoder()\n",
    "player['W_PCT']=label_ratio.fit_transform(player['W_PCT'].astype(str))\n",
    "sns.countplot(x=player['W_PCT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W_PCT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FG3_PCT</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>...</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>BLKA</th>\n",
       "      <th>PF</th>\n",
       "      <th>PFD</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>NBA_FANTASY_PTS</th>\n",
       "      <th>DD2</th>\n",
       "      <th>TD3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.297</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>10.7</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>18.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.275</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>3.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.416</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.357</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>7.3</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>33.4</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.390</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.370</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>11.5</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>23.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>8.9</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.455</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.378</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>25.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>40.4</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>5.9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.431</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>24.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    W_PCT  AGE  FGM   FGA  FG_PCT  FG3M  FG3A  FG3_PCT  FTM  FTA  ...  STL  \\\n",
       "0       1   26  3.7   9.9   0.375   1.2   4.0    0.297  2.1  2.4  ...  0.6   \n",
       "1       2   26  1.4   2.4   0.566   0.0   0.0    0.000  0.4  0.8  ...  0.3   \n",
       "2       1   26  1.6   3.6   0.435   0.1   0.7    0.167  0.9  1.3  ...  0.6   \n",
       "3       1   24  2.3   6.4   0.356   0.8   3.0    0.275  1.1  1.6  ...  0.6   \n",
       "4       2   31  3.8   9.2   0.416   1.6   4.5    0.357  1.2  1.6  ...  0.5   \n",
       "..    ...  ...  ...   ...     ...   ...   ...      ...  ...  ...  ...  ...   \n",
       "60      2   31  1.9   4.3   0.440   0.5   1.1    0.449  0.6  0.7  ...  0.3   \n",
       "61      0   29  7.3  14.3   0.510   0.0   0.0    0.000  2.9  4.1  ...  0.8   \n",
       "62      1   28  4.1  10.5   0.390   2.1   5.8    0.370  1.2  1.5  ...  1.6   \n",
       "63      2   27  8.9  19.5   0.455   1.2   3.3    0.378  6.6  7.9  ...  0.9   \n",
       "64      0   31  5.9  13.0   0.450   1.0   2.2    0.431  2.3  3.0  ...  1.0   \n",
       "\n",
       "    BLK  BLKA   PF  PFD   PTS  PLUS_MINUS  NBA_FANTASY_PTS  DD2  TD3  \n",
       "0   0.1   0.7  1.9  2.1  10.7        -2.8             18.5    2    0  \n",
       "1   0.3   0.3  2.3  0.7   3.1         0.7              9.6    2    0  \n",
       "2   0.0   0.4  1.2  1.2   4.2        -2.6              9.2    0    0  \n",
       "3   0.0   0.2  1.2  1.5   6.5         0.5             12.3    0    0  \n",
       "4   0.1   0.6  2.8  1.5  10.5         1.8             18.6    1    0  \n",
       "..  ...   ...  ...  ...   ...         ...              ...  ...  ...  \n",
       "60  0.0   0.0  1.1  0.8   4.8         1.6              9.8    0    0  \n",
       "61  0.3   1.5  3.2  3.1  17.5         4.7             33.4   30    0  \n",
       "62  0.2   0.6  1.5  1.3  11.5        -1.7             23.8    2    0  \n",
       "63  0.6   1.4  2.9  5.5  25.6         2.4             40.4   18    0  \n",
       "64  0.3   0.7  2.0  2.3  15.0         5.1             24.3    1    0  \n",
       "\n",
       "[65 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.head(65)\n",
    "# label(1,2,0) for low,medium,high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1481\n",
       "2    1016\n",
       "0     352\n",
       "Name: W_PCT, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "player['W_PCT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3, seperate the dataset as response variable and feature variables, get ready for model\n",
    "X=player.drop('W_PCT',axis=1)\n",
    "y=player['W_PCT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4,Use train_test_split(package) to split the data to  Train data and Test data, default test_size 25%\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 5 ,Scale up the data Applying Standart scaling to get optimized result eg, big number overweight the impact of small number\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "# X_test[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6,choose classifier\n",
    "# RANDOM FOREST -Least amount of parts to fine-tune,\n",
    "# used for a medium sized data set\n",
    "# 1,create randomForest variable,2,fit the training data to it,3 predict\n",
    "rfc=RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(X_train,y_train)\n",
    "pred_rfc=rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test[:20]\n",
    "# the test data print out have been sacled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rfc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.19      0.29        74\n",
      "           1       0.75      0.85      0.80       302\n",
      "           2       0.61      0.64      0.63       194\n",
      "\n",
      "    accuracy                           0.69       570\n",
      "   macro avg       0.67      0.56      0.57       570\n",
      "weighted avg       0.69      0.69      0.67       570\n",
      "\n",
      "[[ 14  21  39]\n",
      " [  4 257  41]\n",
      " [  3  66 125]]\n"
     ]
    }
   ],
   "source": [
    "# check the performence of the model\n",
    "print(classification_report(y_test,pred_rfc))\n",
    "print(confusion_matrix(y_test,pred_rfc))\n",
    "# the consusion matrix report shows a lot of miss lable of 'low' and 'high'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM classifier\n",
    "clf=svm.SVC()\n",
    "clf.fit(X_train,y_train)\n",
    "pred_clf=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.05      0.10        74\n",
      "           1       0.73      0.89      0.80       302\n",
      "           2       0.61      0.62      0.62       194\n",
      "\n",
      "    accuracy                           0.69       570\n",
      "   macro avg       0.71      0.52      0.51       570\n",
      "weighted avg       0.70      0.69      0.65       570\n",
      "\n",
      "[[  4  28  42]\n",
      " [  0 268  34]\n",
      " [  1  72 121]]\n"
     ]
    }
   ],
   "source": [
    "# check performence of model\n",
    "print(classification_report(y_test,pred_clf))\n",
    "print(confusion_matrix(y_test,pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.28      0.37        74\n",
      "           1       0.74      0.81      0.77       302\n",
      "           2       0.58      0.59      0.59       194\n",
      "\n",
      "    accuracy                           0.67       570\n",
      "   macro avg       0.61      0.56      0.58       570\n",
      "weighted avg       0.66      0.67      0.66       570\n",
      "\n",
      "[[ 21  20  33]\n",
      " [  8 245  49]\n",
      " [ 11  68 115]]\n"
     ]
    }
   ],
   "source": [
    "# Neural Network classifier\n",
    "# works well with huge amount of data\n",
    "mlpc=MLPClassifier(hidden_layer_sizes=(11,11,11),max_iter=500)\n",
    "mlpc.fit(X_train,y_train)\n",
    "pred_mlpc=mlpc.predict(X_test)\n",
    "print(classification_report(y_test,pred_mlpc))\n",
    "print(confusion_matrix(y_test,pred_mlpc))\n",
    "# A convergence point is a machine learning models localized optimal state. \n",
    "# It basically means that the variables within the model have the best posible values in order to\n",
    "# predict a target feature based on another set of features. In MLP, these variables are the weights within each neuron. \n",
    "# Generally, when a data set doesn't represent a organized and discernable pattern, machine learning algorithms might not be able to find a convergence point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last step, use the choosen model and given new feature data to predict \n",
    "Xnew=[[23,1.6,3.2,0.513,0,0,0,0.6,0.8,0.677,0.8,1.6,2.4,0.3,0.4,0.3,0.5,0.3,0.9,0.8,3.8,-1.8,9.1,1,0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xnew=sc.transform(Xnew)\n",
    "ynew=rfc.predict(Xnew)\n",
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
